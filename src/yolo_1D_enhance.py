import os
import json
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')


# ===================== é…ç½®ï¼ˆä»…ä¿®æ”¹æ­¤å¤„ï¼‰ =====================
class Config:
    DATASET_OUTPUT_DIR = "./modulation_dataset"  # æ•°æ®é›†æ„é€ ç¨‹åºè¾“å‡ºç›®å½•
    BATCH_SIZE = 8  # 8GBæ˜¾å­˜é€‚é…ï¼ˆ12GBå¯è®¾16ï¼Œ24GBå¯è®¾32ï¼‰
    EPOCHS = 5  # æµ‹è¯•ç”¨ï¼Œåƒä¸‡çº§æ ·æœ¬å»ºè®®æ­£å¼è®­ç»ƒè®¾50-100
    LR = 1e-4  # åƒä¸‡çº§æ ·æœ¬å»ºè®®å­¦ä¹ ç‡1e-4~5e-5
    WEIGHT_DECAY = 1e-5  # é˜²æ­¢è¿‡æ‹Ÿåˆ
    ACCUMULATION_STEPS = 4  # æ¢¯åº¦ç´¯ç§¯ï¼Œç­‰æ•ˆå¢å¤§æ‰¹æ¬¡ï¼ˆ48Gå†…å­˜å»ºè®®4-8ï¼‰
    # è‡ªåŠ¨ä»label_mapping.jsonè¯»å–ç±»åˆ«æ•°ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®
    NUM_CLASSES = None


config = Config()


# ===================== æ•°æ®é›†ç±»ï¼ˆé€‚é…åƒä¸‡çº§æ ·æœ¬+48Gå†…å­˜ï¼‰ =====================
class LargeNpyDataset(Dataset):
    """
    å†…å­˜æ˜ å°„æ¨¡å¼åŠ è½½å¤§npyæ–‡ä»¶ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜
    é€‚é…åƒä¸‡çº§æ ·æœ¬ã€48Gå†…å­˜åœºæ™¯ï¼Œä»…æŒ‰éœ€è¯»å–æ ·æœ¬
    """

    def __init__(self, split='train'):
        self.split = split
        self.data_path = os.path.join(config.DATASET_OUTPUT_DIR, f"{split}_data.npy")
        self.labels_path = os.path.join(config.DATASET_OUTPUT_DIR, f"{split}_labels.npy")

        # å†…å­˜æ˜ å°„æ¨¡å¼åŠ è½½ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šä¸å ç‰©ç†å†…å­˜ï¼‰
        self.data = np.load(self.data_path, mmap_mode='r')
        self.labels = np.load(self.labels_path, mmap_mode='r')

        # æ‰“å°æ•°æ®é›†ä¿¡æ¯ï¼ˆé€‚é…ä½ çš„12ç±»è°ƒåˆ¶ä¿¡å·ï¼‰
        self.num_samples = len(self.data)
        self.unique_labels = np.unique(self.labels[:10000])  # é‡‡æ ·ç»Ÿè®¡ç±»åˆ«æ•°
        print(f"âœ… åŠ è½½{split}é›†ï¼š{self.num_samples:,}ä¸ªæ ·æœ¬ | æ£€æµ‹åˆ°{len(self.unique_labels)}ç±»è°ƒåˆ¶ä¿¡å·")

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # æŒ‰éœ€è¯»å–å•æ ·æœ¬ï¼Œé¿å…å†…å­˜æº¢å‡º
        try:
            data = torch.from_numpy(self.data[idx]).float()
            label = torch.tensor(self.labels[idx], dtype=torch.long)
            return data, label
        except Exception as e:
            # å®¹é”™ï¼šæ ·æœ¬è¯»å–å¤±è´¥æ—¶è¿”å›ç©ºæ ·æœ¬ï¼ˆé¿å…è®­ç»ƒä¸­æ–­ï¼‰
            print(f"âš ï¸  è¯»å–{self.split}é›†æ ·æœ¬{idx}å¤±è´¥ï¼š{e}")
            return torch.zeros(2, config.SAMPLE_LENGTH).float(), torch.tensor(0, dtype=torch.long)


# ===================== æ¨¡å‹å®šä¹‰ï¼ˆå…¼å®¹12ç±»è°ƒåˆ¶ä¿¡å·ï¼‰ =====================
class Swish(nn.Module):
    """ä½ç‰ˆæœ¬PyTorchå…¼å®¹SiLU"""

    def forward(self, x):
        return x * torch.sigmoid(x)


def get_activation():
    return nn.SiLU() if hasattr(nn, 'SiLU') else Swish()


class YOLO12_1D_Classifier(nn.Module):
    """è½»é‡åŒ–YOLO12-1Dæ¨¡å‹ï¼ˆé€‚é…12ç±»è°ƒåˆ¶ä¿¡å·åˆ†ç±»ï¼‰"""

    def __init__(self, num_classes=12):
        super().__init__()
        self.backbone = nn.Sequential(
            nn.Conv1d(2, 16, 6, 2, 3, bias=False),  # è¾“å…¥ï¼š2é€šé“ï¼ˆI/Qï¼‰ï¼Œ4096é•¿åº¦
            nn.BatchNorm1d(16),
            get_activation(),
            nn.Conv1d(16, 32, 3, 2, 1, bias=False),
            nn.BatchNorm1d(32),
            get_activation(),
            nn.Conv1d(32, 64, 3, 2, 1, bias=False),
            nn.BatchNorm1d(64),
            get_activation(),
            nn.Conv1d(64, 128, 3, 2, 1, bias=False),
            nn.BatchNorm1d(128),
            get_activation(),
            nn.Conv1d(128, 128, 3, 2, 1, bias=False),
            nn.BatchNorm1d(128),
            get_activation(),
        )
        self.class_head = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),  # é€‚é…ä»»æ„é•¿åº¦è¾“å…¥
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.LayerNorm(64),
            get_activation(),
            nn.Dropout(0.1),  # åƒä¸‡çº§æ ·æœ¬å»ºè®®dropout 0.1-0.2
            nn.Linear(64, num_classes)
        )
        # æƒé‡åˆå§‹åŒ–ï¼ˆé€‚é…åˆ†ç±»ä»»åŠ¡ï¼‰
        self.apply(lambda m: nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')
        if isinstance(m, (nn.Conv1d, nn.Linear)) else None)
        # è‡ªåŠ¨é€‚é…è®¾å¤‡ï¼ˆGPU/CPUï¼‰
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.to(self.device)

    def forward(self, x):
        return self.class_head(self.backbone(x.to(self.device)))


# ===================== è®­ç»ƒå‡½æ•°ï¼ˆé€‚é…åƒä¸‡çº§æ ·æœ¬ï¼‰ =====================
def train_model():
    """ä¸»è®­ç»ƒå‡½æ•°ï¼šé€‚é…12ç±»è°ƒåˆ¶ä¿¡å·ã€åƒä¸‡çº§æ ·æœ¬ã€48Gå†…å­˜"""
    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹è®­ç»ƒï¼ˆé€‚é…åƒä¸‡çº§è°ƒåˆ¶ä¿¡å·æ•°æ®é›†ï¼‰")
    print("=" * 80)

    # -------------------------- 1. åˆå§‹åŒ–é…ç½®ï¼ˆè‡ªåŠ¨é€‚é…ä½ çš„æ•°æ®é›†ï¼‰ --------------------------
    # è‡ªåŠ¨è¯»å–æ ·æœ¬é•¿åº¦ï¼ˆä»file_metadata.csvæˆ–label_mapping.jsonï¼‰
    try:
        label_mapping_path = os.path.join(config.DATASET_OUTPUT_DIR, "label_mapping.json")
        with open(label_mapping_path, 'r', encoding='utf-8') as f:
            label_mapping = json.load(f)
        config.NUM_CLASSES = len(label_mapping['label_to_idx'])
        config.SAMPLE_LENGTH = 4096  # ä½ çš„æ•°æ®é›†å›ºå®š4096é•¿åº¦
        print(f"ğŸ“Œ è‡ªåŠ¨è¯†åˆ«ï¼š{config.NUM_CLASSES}ç±»è°ƒåˆ¶ä¿¡å· | å•æ ·æœ¬é•¿åº¦{config.SAMPLE_LENGTH}")
    except Exception as e:
        print(f"âš ï¸  è¯»å–æ ‡ç­¾æ˜ å°„å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤12ç±»ï¼š{e}")
        config.NUM_CLASSES = 12
        config.SAMPLE_LENGTH = 4096

    # æ ¡éªŒæ•°æ®é›†æ–‡ä»¶ï¼ˆé€‚é…ä½ çš„æµå¼ç”Ÿæˆç»“æœï¼‰
    required_npy = [
        "train_data.npy", "train_labels.npy",
        "val_data.npy", "val_labels.npy",
        "test_data.npy", "test_labels.npy"
    ]
    missing_files = []
    for f in required_npy:
        file_path = os.path.join(config.DATASET_OUTPUT_DIR, f)
        if not os.path.exists(file_path):
            missing_files.append(f)
    if missing_files:
        raise FileNotFoundError(f"âŒ ç¼ºå¤±æ•°æ®é›†æ–‡ä»¶ï¼š{missing_files}ï¼Œè¯·å…ˆè¿è¡Œdataset_constructor.py")

    # -------------------------- 2. è®¾å¤‡é€‚é…ï¼ˆWindows+48Gå†…å­˜ï¼‰ --------------------------
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:512"  # æ˜¾å­˜åˆ†ç‰‡ï¼Œé¿å…OOM
    torch.backends.cudnn.benchmark = True  # åŠ é€Ÿè®­ç»ƒ
    torch.multiprocessing.set_sharing_strategy('file_system')  # Windowså†…å­˜æ˜ å°„å…¼å®¹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“Œ è®­ç»ƒè®¾å¤‡ï¼š{device} ({torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'})")
    if not torch.cuda.is_available():
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆåƒä¸‡çº§æ ·æœ¬CPUè®­ç»ƒææ…¢ï¼‰")

    # -------------------------- 3. åŠ è½½æ•°æ®é›†ï¼ˆå†…å­˜æ˜ å°„æ¨¡å¼ï¼‰ --------------------------
    print("\nğŸ“Œ åŠ è½½æ•°æ®é›†ï¼ˆå†…å­˜æ˜ å°„æ¨¡å¼ï¼Œ48Gå†…å­˜å‹å¥½ï¼‰")
    train_dataset = LargeNpyDataset('train')
    val_dataset = LargeNpyDataset('val')
    test_dataset = LargeNpyDataset('test')

    # DataLoaderï¼ˆé€‚é…åƒä¸‡çº§æ ·æœ¬ï¼Œå…³é—­å¤šè¿›ç¨‹é¿å…å†…å­˜å†²çªï¼‰
    train_loader = DataLoader(
        train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,
        num_workers=0, pin_memory=False, drop_last=True,  # num_workers=0é€‚é…Windows
        prefetch_factor=None  # å…³é—­é¢„å–ï¼Œå‡å°‘å†…å­˜å ç”¨
    )
    val_loader = DataLoader(
        val_dataset, batch_size=config.BATCH_SIZE * 2, shuffle=False,
        num_workers=0, pin_memory=False
    )
    test_loader = DataLoader(
        test_dataset, batch_size=config.BATCH_SIZE * 2, shuffle=False,
        num_workers=0, pin_memory=False
    )

    # -------------------------- 4. æ¨¡å‹/ä¼˜åŒ–å™¨åˆå§‹åŒ– --------------------------
    model = YOLO12_1D_Classifier(num_classes=config.NUM_CLASSES)
    criterion = nn.CrossEntropyLoss().to(device)
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.LR,
        weight_decay=config.WEIGHT_DECAY,
        eps=1e-8  # é€‚é…åƒä¸‡çº§æ ·æœ¬ä¼˜åŒ–
    )
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=config.EPOCHS, eta_min=1e-6  # å­¦ä¹ ç‡ä½™å¼¦è¡°å‡
    )
    scaler = GradScaler()  # æ··åˆç²¾åº¦è®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜

    # -------------------------- 5. è®­ç»ƒå¾ªç¯ï¼ˆé€‚é…åƒä¸‡çº§æ ·æœ¬ï¼‰ --------------------------
    best_val_acc = 0.0
    print(f"\nğŸ“Œ å¼€å§‹è®­ç»ƒï¼š{config.EPOCHS}è½® | æ‰¹æ¬¡å¤§å°{config.BATCH_SIZE} | æ¢¯åº¦ç´¯ç§¯{config.ACCUMULATION_STEPS}")

    for epoch in range(config.EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss, train_acc, train_total = 0.0, 0.0, 0
        pbar = tqdm(train_loader, desc=f"Epoch [{epoch + 1}/{config.EPOCHS}] Train")

        optimizer.zero_grad()
        for batch_idx, (data, labels) in enumerate(pbar):
            # å®šæœŸæ¸…ç†æ˜¾å­˜ï¼ˆé€‚é…åƒä¸‡çº§æ ·æœ¬ï¼‰
            if batch_idx % 50 == 0:
                torch.cuda.empty_cache()

            # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆæ ¸å¿ƒï¼šå‡å°‘æ˜¾å­˜å ç”¨ï¼‰
            with autocast():
                outputs = model(data)
                loss = criterion(outputs, labels.to(device)) / config.ACCUMULATION_STEPS

            # æ¢¯åº¦ç´¯ç§¯ï¼ˆç­‰æ•ˆå¢å¤§æ‰¹æ¬¡ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ï¼‰
            scaler.scale(loss).backward()
            if (batch_idx + 1) % config.ACCUMULATION_STEPS == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()

            # ç»Ÿè®¡è®­ç»ƒæŒ‡æ ‡
            train_loss += loss.item() * config.ACCUMULATION_STEPS * data.size(0)
            train_acc += (outputs.argmax(1) == labels.to(device)).sum().item()
            train_total += data.size(0)

            # å®æ—¶æ˜¾ç¤ºæ˜¾å­˜å ç”¨
            mem_used = torch.cuda.memory_allocated(0) / 1e9 if torch.cuda.is_available() else 0
            pbar.set_postfix({
                'Loss': f'{loss.item() * config.ACCUMULATION_STEPS:.4f}',
                'Acc': f'{train_acc / train_total:.4f}',
                'Mem': f'{mem_used:.1f}GB'
            })

        # éªŒè¯é˜¶æ®µï¼ˆæ— æ¢¯åº¦è®¡ç®—ï¼‰
        model.eval()
        val_loss, val_acc, val_total = 0.0, 0.0, 0
        with torch.no_grad():
            for data, labels in tqdm(val_loader, desc=f"Epoch [{epoch + 1}/{config.EPOCHS}] Val"):
                outputs = model(data)
                loss = criterion(outputs, labels.to(device))
                val_loss += loss.item() * data.size(0)
                val_acc += (outputs.argmax(1) == labels.to(device)).sum().item()
                val_total += data.size(0)

        # è®¡ç®—æœ¬è½®æŒ‡æ ‡
        train_loss_avg = train_loss / train_total
        train_acc_avg = train_acc / train_total
        val_loss_avg = val_loss / val_total
        val_acc_avg = val_acc / val_total
        scheduler.step()  # å­¦ä¹ ç‡è¡°å‡

        # æ‰“å°æœ¬è½®ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch + 1} è®­ç»ƒç»“æœï¼š")
        print(f"  - è®­ç»ƒæŸå¤±ï¼š{train_loss_avg:.4f} | è®­ç»ƒå‡†ç¡®ç‡ï¼š{train_acc_avg:.4f}")
        print(f"  - éªŒè¯æŸå¤±ï¼š{val_loss_avg:.4f} | éªŒè¯å‡†ç¡®ç‡ï¼š{val_acc_avg:.4f}")
        print(f"  - å½“å‰å­¦ä¹ ç‡ï¼š{optimizer.param_groups[0]['lr']:.6f}")

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆæŒ‰éªŒè¯å‡†ç¡®ç‡ï¼‰
        if val_acc_avg > best_val_acc:
            best_val_acc = val_acc_avg
            save_path = os.path.join(config.DATASET_OUTPUT_DIR, "yolo12_1d_best.pth")
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_acc': best_val_acc,
                'num_classes': config.NUM_CLASSES,
                'sample_length': config.SAMPLE_LENGTH
            }, save_path)
            print(f"âœ… ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼š{save_path}ï¼ˆéªŒè¯å‡†ç¡®ç‡ï¼š{best_val_acc:.4f}ï¼‰")

    # -------------------------- 6. æµ‹è¯•é˜¶æ®µï¼ˆåŠ è½½æœ€ä¼˜æ¨¡å‹ï¼‰ --------------------------
    print("\nğŸ“Œ æµ‹è¯•é˜¶æ®µï¼ˆåŠ è½½æœ€ä¼˜æ¨¡å‹è¯„ä¼°ï¼‰")
    checkpoint = torch.load(os.path.join(config.DATASET_OUTPUT_DIR, "yolo12_1d_best.pth"), map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    test_acc, test_total = 0.0, 0
    with torch.no_grad():
        for data, labels in tqdm(test_loader, desc="Testing"):
            outputs = model(data)
            test_acc += (outputs.argmax(1) == labels.to(device)).sum().item()
            test_total += data.size(0)
    test_acc_avg = test_acc / test_total

    # -------------------------- 7. æœ€ç»ˆç»“æœè¾“å‡º --------------------------
    print("\n" + "=" * 80)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ç»ˆç»“æœï¼ˆé€‚é…åƒä¸‡çº§è°ƒåˆ¶ä¿¡å·æ•°æ®é›†ï¼‰ï¼š")
    print(f"  - æœ€ä¼˜éªŒè¯å‡†ç¡®ç‡ï¼š{best_val_acc:.4f}")
    print(f"  - æµ‹è¯•é›†å‡†ç¡®ç‡ï¼š{test_acc_avg:.4f}")
    print(f"  - è°ƒåˆ¶ç±»åˆ«æ•°ï¼š{config.NUM_CLASSES}")
    print(f"  - æœ€ä¼˜æ¨¡å‹è·¯å¾„ï¼š{os.path.join(config.DATASET_OUTPUT_DIR, 'yolo12_1d_best.pth')}")
    print("=" * 80)


# ===================== è¿è¡Œå…¥å£ =====================
if __name__ == "__main__":
    # å†…å­˜ä¿æŠ¤ï¼šé™åˆ¶PyTorchå†…å­˜å ç”¨ï¼ˆ48Gå†…å­˜å»ºè®®è®¾ä¸º32Gï¼‰
    if torch.cuda.is_available():
        torch.cuda.set_per_process_memory_fraction(0.8)  # æœ€å¤šä½¿ç”¨80%GPUæ˜¾å­˜
    train_model()