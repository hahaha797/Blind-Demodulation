import torch
import numpy as np
import pandas as pd
import json
from torch.utils.data import Dataset, DataLoader

# -------------------------- é…ç½®å‚æ•° --------------------------
METADATA_DIR = "./modulation_metadata"
SAMPLE_LENGTH = 4096  # 4096å¯¹IQæ•°æ®/æ ·æœ¬


# -------------------------- åŠ¨æ€åŠ è½½Datasetç±» --------------------------
class DynamicSlidingWindowDataset(Dataset):
    """
    åŠ¨æ€æ»‘åŠ¨çª—å£åŠ è½½æ•°æ®é›†ï¼ˆæ­¥é•¿1ï¼‰
    æ ¸å¿ƒï¼šè®¿é—®æ ·æœ¬æ—¶æ‰ä»åŸå§‹æ–‡ä»¶æå–å¯¹åº”ä½ç½®çš„4096å¯¹IQæ•°æ®ï¼Œä¸é¢„å…ˆä¿å­˜æ‰€æœ‰æ ·æœ¬
    """

    def __init__(self, split='train', test_size=0.2, val_size=0.125, random_state=42):
        # åŠ è½½å…ƒæ•°æ®
        self.sample_mapping = pd.read_csv(f"{METADATA_DIR}/global_sample_mapping.csv")
        self.label_mapping = json.load(open(f"{METADATA_DIR}/label_mapping.json", 'r'))
        self.total_samples = self.label_mapping['total_samples']
        self.label_to_idx = self.label_mapping['label_to_idx']

        # åˆ†å±‚åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆä¿è¯è°ƒåˆ¶ç±»å‹åˆ†å¸ƒå‡åŒ€ï¼‰
        from sklearn.model_selection import train_test_split

        # æŒ‰è°ƒåˆ¶ç±»å‹åˆ†ç»„ï¼Œåˆ†å±‚åˆ’åˆ†
        self.sample_mapping['label_idx'] = self.sample_mapping['modulation'].map(self.label_to_idx)
        X = self.sample_mapping['global_idx'].values
        y = self.sample_mapping['label_idx'].values

        # ç¬¬ä¸€æ­¥ï¼šåˆ’åˆ†è®­ç»ƒ+éªŒè¯é›† å’Œ æµ‹è¯•é›†
        X_train_val, X_test, y_train_val, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )

        # ç¬¬äºŒæ­¥ï¼šåˆ’åˆ†è®­ç»ƒé›† å’Œ éªŒè¯é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_val, y_train_val, test_size=val_size, random_state=random_state, stratify=y_train_val
        )

        # ç¡®å®šå½“å‰æ•°æ®é›†çš„æ ·æœ¬ç´¢å¼•
        if split == 'train':
            self.selected_idxs = X_train
        elif split == 'val':
            self.selected_idxs = X_val
        elif split == 'test':
            self.selected_idxs = X_test
        else:
            raise ValueError(f"split must be 'train'/'val'/'test', got {split}")

        # æ„å»ºç´¢å¼•æ˜ å°„ï¼šDatasetç´¢å¼• â†’ å…¨å±€æ ·æœ¬ç´¢å¼•
        self.idx_map = {ds_idx: global_idx for ds_idx, global_idx in enumerate(self.selected_idxs)}
        print(f"âœ… {split}é›†åˆå§‹åŒ–å®Œæˆï¼š{len(self.selected_idxs)}ä¸ªæ ·æœ¬")

    def __len__(self):
        return len(self.selected_idxs)

    def _read_iq_data(self, file_path, start_idx, length):
        """ä»æŒ‡å®šæ–‡ä»¶çš„æŒ‡å®šèµ·å§‹ä½ç½®è¯»å–lengthå¯¹IQæ•°æ®"""
        try:
            if file_path.endswith('.bin'):
                with open(file_path, 'rb') as f:
                    data = np.fromfile(f, dtype=np.int16)
                iq_data = data.reshape(-1, 2)

            elif file_path.endswith('.wav'):
                with open(file_path, 'rb') as f:
                    f.seek(1068)  # è·³è¿‡å¤´éƒ¨
                    data = np.fromfile(f, dtype=np.int16)
                iq_data = data.reshape(-1, 2)

            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_path}")

            # æå–æŒ‡å®šä½ç½®çš„IQæ•°æ®
            end_idx = start_idx + length
            if end_idx > len(iq_data):
                # è¾¹ç•Œå¤„ç†ï¼šä¸è¶³æ—¶è¡¥0ï¼ˆå®é™…ä¸ä¼šè§¦å‘ï¼Œå…ƒæ•°æ®å·²è¿‡æ»¤ï¼‰
                sample = np.zeros((length, 2), dtype=np.int16)
                valid_len = len(iq_data) - start_idx
                sample[:valid_len] = iq_data[start_idx:]
            else:
                sample = iq_data[start_idx:end_idx]

            # å½’ä¸€åŒ–ï¼šshort(-32768~32767) â†’ float32(-1.0~1.0)
            sample_norm = sample.astype(np.float32) / 32767.0
            return sample_norm

        except Exception as e:
            print(f"âš ï¸  è¯»å–IQæ•°æ®å¤±è´¥ï¼š{file_path} start={start_idx} â†’ {str(e)}")
            return np.zeros((length, 2), dtype=np.float32)

    def __getitem__(self, idx):
        # 1. è·å–å…¨å±€æ ·æœ¬ç´¢å¼•
        global_idx = self.idx_map[idx]

        # 2. æŸ¥æ‰¾è¯¥æ ·æœ¬å¯¹åº”çš„æ–‡ä»¶å’Œèµ·å§‹ä½ç½®
        sample_info = self.sample_mapping[self.sample_mapping['global_idx'] == global_idx].iloc[0]
        file_path = sample_info['file_path']
        start_iq_idx = int(sample_info['start_iq_idx'])
        modulation = sample_info['modulation']
        label_idx = self.label_to_idx[modulation]

        # 3. åŠ¨æ€è¯»å–IQæ•°æ®ï¼ˆæ­¥é•¿1çš„4096å¯¹IQï¼‰
        iq_data = self._read_iq_data(file_path, start_iq_idx, SAMPLE_LENGTH)

        # 4. è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼ˆC, Lï¼‰â†’ é€šé“åœ¨å‰
        sample_tensor = torch.from_numpy(iq_data).permute(1, 0).float()
        label_tensor = torch.tensor(label_idx, dtype=torch.long)

        return sample_tensor, label_tensor


# -------------------------- æµ‹è¯•åŠ è½½ï¼ˆæŸ¥çœ‹å½¢çŠ¶ï¼‰ --------------------------
def dynamic_loading():
    print("=" * 70)
    print("ğŸ“Š æµ‹è¯•åŠ¨æ€æ»‘åŠ¨çª—å£åŠ è½½ï¼ˆæ­¥é•¿1ï¼‰")
    print("=" * 70)

    # åˆå§‹åŒ–è®­ç»ƒé›†
    train_dataset = DynamicSlidingWindowDataset(split='train')
    val_dataset = DynamicSlidingWindowDataset(split='val')
    test_dataset = DynamicSlidingWindowDataset(split='test')

    # æŸ¥çœ‹å•ä¸ªæ ·æœ¬å½¢çŠ¶
    sample, label = train_dataset[0]
    print(f"ğŸ” å•ä¸ªæ ·æœ¬å½¢çŠ¶ï¼š{sample.shape} â†’ (é€šé“æ•°=2, åºåˆ—é•¿åº¦=4096)")
    print(f"ğŸ” å•ä¸ªæ ·æœ¬æ ‡ç­¾ï¼š{label.item()} â†’ {train_dataset.label_mapping['idx_to_label'][str(label.item())]}")

    # æ‰¹é‡åŠ è½½æµ‹è¯•
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)
    batch_data, batch_labels = next(iter(train_loader))
    print(f"\nğŸ“¦ æ‰¹é‡åŠ è½½å½¢çŠ¶ï¼š")
    print(f"  - æ‰¹é‡ç‰¹å¾ï¼š{batch_data.shape} â†’ (batch_size=16, é€šé“æ•°=2, åºåˆ—é•¿åº¦=4096)")
    print(f"  - æ‰¹é‡æ ‡ç­¾ï¼š{batch_labels.shape} â†’ (batch_size=16,)")
    print(f"  - æ‰¹é‡æ ‡ç­¾ç¤ºä¾‹ï¼š{batch_labels[:5].numpy()}")

    # æ•°æ®é›†å¤§å°ç»Ÿè®¡
    print(f"\nğŸ“ˆ æ•°æ®é›†å¤§å°ï¼š")
    print(f"  - è®­ç»ƒé›†ï¼š{len(train_dataset)} æ ·æœ¬")
    print(f"  - éªŒè¯é›†ï¼š{len(val_dataset)} æ ·æœ¬")
    print(f"  - æµ‹è¯•é›†ï¼š{len(test_dataset)} æ ·æœ¬")

    print("\n" + "=" * 70)
    print("âœ… åŠ¨æ€æ»‘åŠ¨çª—å£åŠ è½½æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    dynamic_loading()