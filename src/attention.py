import os
import json
import time
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from tqdm import tqdm
import warnings
import psutil
from datetime import datetime

warnings.filterwarnings('ignore')


# ===================== 1. ÈÖçÁΩÆÂèÇÊï∞ =====================
class Config:
    # Êï∞ÊçÆÈõÜË∑ØÂæÑ
    DATASET_OUTPUT_DIR = "./modulation_dataset_50overlap"
    LOG_DIR = "./train_logs"

    # ËÆ≠ÁªÉË∂ÖÂèÇÊï∞
    BATCH_SIZE = 64  # Ê†πÊçÆÊòæÂ≠òË∞ÉÊï¥ (48GÊòæÂ≠òÂèØËÆæ 64~128)
    EPOCHS = 50
    LR = 3e-4  # ÂàùÂßãÂ≠¶‰π†Áéá
    WEIGHT_DECAY = 1e-4
    ACCUMULATION_STEPS = 4  # Ê¢ØÂ∫¶Á¥ØÁßØÔºåÁ≠âÊïà Batch Size = 256

    # Ëá™Âä®Ëé∑ÂèñÁöÑÂèÇÊï∞
    NUM_CLASSES = 0  # Á®çÂêé‰ªé json ËØªÂèñ
    SAMPLE_LENGTH = 4096  # Ê†∑Êú¨ÈïøÂ∫¶

    # Á≥ªÁªüÂèÇÊï∞
    SAVE_INTERVAL = 5
    NUM_WORKERS = 0 if os.name == 'nt' else 4


config = Config()
os.makedirs(config.LOG_DIR, exist_ok=True)


# ===================== 2. Â∑•ÂÖ∑ÂáΩÊï∞ =====================
def log_info(msg, save_to_file=True):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_msg = f"[{timestamp}] {msg}"
    print(log_msg)
    if save_to_file:
        with open(os.path.join(config.LOG_DIR, "train_log.txt"), 'a', encoding='utf-8') as f:
            f.write(log_msg + "\n")


def monitor_resources():
    mem_info = "CPU"
    if torch.cuda.is_available():
        mem_alloc = torch.cuda.memory_allocated(0) / 1024 ** 3
        mem_res = torch.cuda.memory_reserved(0) / 1024 ** 3
        mem_info = f"GPU: {mem_alloc:.1f}/{mem_res:.1f}GB"
    ram_used = psutil.virtual_memory().percent
    return f"{mem_info} | RAM: {ram_used}%"


# ===================== 3. Êï∞ÊçÆÈõÜ (Float16 Support) =====================
class ModulationDataset(Dataset):
    def __init__(self, split='train'):
        self.split = split
        self.data_path = os.path.join(config.DATASET_OUTPUT_DIR, f"{split}_data.npy")
        self.labels_path = os.path.join(config.DATASET_OUTPUT_DIR, f"{split}_labels.npy")

        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"‚ùå {split}ÈõÜÊñá‰ª∂Áº∫Â§±Ôºö{self.data_path}")

        try:
            # mmap_mode='r': ÂÜÖÂ≠òÊò†Â∞ÑÔºå‰∏ç‰∏ÄÊ¨°ÊÄßÂä†ËΩΩËøõÂÜÖÂ≠ò
            self.data = np.load(self.data_path, mmap_mode='r')
            self.labels = np.load(self.labels_path, mmap_mode='r')
        except Exception as e:
            raise RuntimeError(f"‚ùå Âä†ËΩΩ{split}ÈõÜÂ§±Ë¥•Ôºö{e}")

        self.num_samples = len(self.labels)
        log_info(f"‚úÖ Loaded {split}: {self.num_samples:,} samples | Shape: {self.data.shape}")

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        try:
            # ËØªÂèñÊï∞ÊçÆÂπ∂ËΩ¨‰∏∫ Float32 (Ê®°ÂûãËÆ°ÁÆóÈúÄË¶Å)
            sample_np = self.data[idx].astype(np.float32)
            label_val = self.labels[idx]
            return torch.from_numpy(sample_np), torch.tensor(label_val, dtype=torch.long)
        except:
            return torch.zeros(2, config.SAMPLE_LENGTH).float(), torch.tensor(0).long()


# ===================== 4. Ê®°ÂûãÁªÑ‰ª∂ (SE-Block & Multi-Domain) =====================

class Swish(nn.Module):
    def forward(self, x): return x * torch.sigmoid(x)


def get_activation():
    return nn.SiLU() if hasattr(nn, 'SiLU') else Swish()


class SEBlock1D(nn.Module):
    """ ÈÄöÈÅìÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºöËÆ©Ê®°ÂûãÂ≠¶‰π†‚ÄúÂì™‰∏™ÈÄöÈÅìÊõ¥ÈáçË¶Å‚Äù """

    def __init__(self, channel, reduction=16):
        super(SEBlock1D, self).__init__()
        reduced_channel = max(channel // reduction, 4)
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, reduced_channel, bias=False),
            get_activation(),
            nn.Linear(reduced_channel, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y.expand_as(x)


class MultiDomainEmbedding(nn.Module):
    """
    Â§öÂüüÁâπÂæÅÊèêÂèñÂ±Ç
    Â∞ÜÂéüÂßã I/Q ‰ø°Âè∑Êâ©Â±ï‰∏∫ [Time, FFT, Wavelet] Ê∑∑ÂêàÁâπÂæÅ
    ËæìÂá∫ÈÄöÈÅìÊï∞: 2 (ÂéüÂßã) + 1 (FFT) + 4 (Wavelet) = 7
    """

    def __init__(self):
        super().__init__()
        # Haar Â∞èÊ≥¢Ê†∏: Low-pass (ÂùáÂÄº/Ëøë‰ºº), High-pass (Â∑ÆÂàÜ/ÁªÜËäÇ)
        self.register_buffer('haar_weights', torch.tensor([
            [[0.70710678, 0.70710678]],  # Low
            [[0.70710678, -0.70710678]]  # High
        ]).float())  # Shape: [2, 1, 2]

    def forward(self, x):
        # Input x: [B, 2, L]
        B, C, L = x.shape

        # --- 1. È¢ëÂüüÁâπÂæÅ (FFT) ---
        # ÊûÑÈÄ†Â§çÊï∞
        x_complex = torch.complex(x[:, 0, :], x[:, 1, :])
        # FFT ÂèòÊç¢ -> ÂèñÊ®° -> ÂØπÊï∞Áº©Êîæ (log1p)
        fft_mag = torch.abs(torch.fft.fft(x_complex, dim=-1, norm='ortho'))
        fft_feature = torch.log1p(fft_mag).unsqueeze(1)  # [B, 1, L]

        # --- 2. Êó∂È¢ëÁâπÂæÅ (Wavelet) ---
        # Â∞Ü I, Q ËßÜ‰∏∫Áã¨Á´ãÈÄöÈÅìÂ§ÑÁêÜ
        x_reshaped = x.view(B * 2, 1, L)
        # Padding ‰øùÊåÅÂç∑ÁßØÂêéÈïøÂ∫¶‰∏çÂèò (L)
        x_pad = F.pad(x_reshaped, (0, 1), mode='replicate')
        # Âç∑ÁßØÊèêÂèñ Haar ÁâπÂæÅ
        wavelet_out = F.conv1d(x_pad, self.haar_weights, stride=1)  # [B*2, 2, L]
        # Reshape Âõû [B, 4, L] (I-Low, I-High, Q-Low, Q-High)
        wavelet_feature = wavelet_out.view(B, 4, L)

        # --- 3. ÊãºÊé•ËûçÂêà ---
        # [B, 2+1+4, L] -> [B, 7, L]
        return torch.cat([x, fft_feature, wavelet_feature], dim=1)


class BLDE_1D_Modulation(nn.Module):
    def __init__(self, num_classes):
        super().__init__()

        # ÂµåÂÖ•Â±Ç
        self.embedding = MultiDomainEmbedding()

        # Backbone: Input Channels = 7
        self.features = nn.Sequential(
            # Stage 1: 7 -> 32
            nn.Conv1d(7, 32, 7, stride=2, padding=3, bias=False),  # -> 2048
            nn.BatchNorm1d(32), get_activation(),
            SEBlock1D(32, reduction=4),

            # Stage 2: 32 -> 64
            nn.Conv1d(32, 64, 5, stride=2, padding=2, bias=False),  # -> 1024
            nn.BatchNorm1d(64), get_activation(),
            SEBlock1D(64, reduction=8),
            nn.Dropout1d(0.1),

            # Stage 3: 64 -> 128
            nn.Conv1d(64, 128, 3, stride=2, padding=1, bias=False),  # -> 512
            nn.BatchNorm1d(128), get_activation(),
            SEBlock1D(128, reduction=16),

            # Stage 4: 128 -> 256
            nn.Conv1d(128, 256, 3, stride=2, padding=1, bias=False),  # -> 256
            nn.BatchNorm1d(256), get_activation(),
            SEBlock1D(256, reduction=16),

            # Stage 5: 256 -> 512
            nn.Conv1d(256, 512, 3, stride=2, padding=1, bias=False),  # -> 128
            nn.BatchNorm1d(512), get_activation(),
            SEBlock1D(512, reduction=16),

            # Stage 6: 512 -> 512
            nn.Conv1d(512, 512, 3, stride=2, padding=1, bias=False),  # -> 64
            nn.BatchNorm1d(512), get_activation(),
            SEBlock1D(512, reduction=16),
        )

        # Classifier Head
        self.avgpool = nn.AdaptiveAvgPool1d(1)
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512, 256),
            nn.LayerNorm(256),
            get_activation(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )

        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.embedding(x)  # [B, 7, L]
        x = self.features(x)
        x = self.avgpool(x)
        return self.classifier(x)


# ===================== 5. ËÆ≠ÁªÉ‰∏ªÁ®ãÂ∫è =====================
def train_model():
    log_info("=" * 60)
    log_info("üöÄ ÂºÄÂßãËÆ≠ÁªÉ: Multi-Domain (Time+FFT+Wavelet) + SE-Attn + Float16")
    log_info("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    log_info(f"Using device: {device}")

    # --- 1. ËØªÂèñÁ±ªÂà´Êò†Â∞Ñ ---
    json_path = os.path.join(config.DATASET_OUTPUT_DIR, "label_mapping.json")
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            mapping = json.load(f)
            if 'label_to_idx' in mapping:
                config.NUM_CLASSES = len(mapping['label_to_idx'])
            elif isinstance(mapping, dict):
                config.NUM_CLASSES = len(mapping)
        log_info(f"üìå Detected Classes: {config.NUM_CLASSES}")
    else:
        log_info("‚ö†Ô∏è label_mapping.json missing, defaulting to 20 classes")
        config.NUM_CLASSES = 20

    # --- 2. Âä†ËΩΩÊï∞ÊçÆ ---
    train_loader = DataLoader(ModulationDataset('train'), batch_size=config.BATCH_SIZE,
                              shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)
    val_loader = DataLoader(ModulationDataset('val'), batch_size=config.BATCH_SIZE * 2,
                            shuffle=False, num_workers=config.NUM_WORKERS, pin_memory=True)
    test_loader = DataLoader(ModulationDataset('test'), batch_size=config.BATCH_SIZE * 2,
                             shuffle=False, num_workers=config.NUM_WORKERS, pin_memory=True)

    # --- 3. ÂàùÂßãÂåñÊ®°Âûã ---
    model = BLDE_1D_Modulation(num_classes=config.NUM_CLASSES).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    # One Cycle Â≠¶‰π†ÁéáË∞ÉÂ∫¶
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=config.LR,
        steps_per_epoch=len(train_loader) // config.ACCUMULATION_STEPS,
        epochs=config.EPOCHS, pct_start=0.1
    )

    scaler = GradScaler()  # Ê∑∑ÂêàÁ≤æÂ∫¶

    # --- 4. ËÆ≠ÁªÉÂæ™ÁéØ ---
    best_acc = 0.0

    for epoch in range(config.EPOCHS):
        model.train()
        total_loss, correct, total = 0, 0, 0
        optimizer.zero_grad()

        pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{config.EPOCHS}", ncols=110)

        for i, (inputs, targets) in enumerate(pbar):
            inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)

            with autocast():  # Ê∑∑ÂêàÁ≤æÂ∫¶ÂâçÂêë
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                loss = loss / config.ACCUMULATION_STEPS

            scaler.scale(loss).backward()

            if (i + 1) % config.ACCUMULATION_STEPS == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()
                scheduler.step()

            scaler_loss = loss.item() * config.ACCUMULATION_STEPS
            total_loss += scaler_loss
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            pbar.set_postfix({'Loss': f"{scaler_loss:.4f}", 'Acc': f"{100. * correct / total:.2f}%"})

        # Epoch ÁªìÊùüÁªüËÆ°
        train_acc = 100. * correct / total
        log_info(
            f"Epoch {epoch + 1} Train | Loss: {total_loss / len(train_loader):.4f} | Acc: {train_acc:.2f}% | {monitor_resources()}")

        # È™åËØÅ
        val_acc = evaluate(model, val_loader, device, criterion, "Val")

        # ‰øùÂ≠òÊúÄ‰ºò
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), os.path.join(config.DATASET_OUTPUT_DIR, "best_model.pth"))
            log_info(f"‚úÖ Best Model Saved! Acc: {best_acc:.2f}%")

        # ÂÆöÊúü‰øùÂ≠ò
        if (epoch + 1) % config.SAVE_INTERVAL == 0:
            torch.save(model.state_dict(), os.path.join(config.DATASET_OUTPUT_DIR, f"epoch_{epoch + 1}.pth"))

    # ÊµãËØï
    log_info("Starting Final Test...")
    model.load_state_dict(torch.load(os.path.join(config.DATASET_OUTPUT_DIR, "best_model.pth")))
    evaluate(model, test_loader, device, criterion, "Test")


def evaluate(model, loader, device, criterion, name="Val"):
    model.eval()
    total_loss, correct, total = 0, 0, 0
    with torch.no_grad():
        for inputs, targets in tqdm(loader, desc=name, ncols=100, leave=False):
            inputs, targets = inputs.to(device), targets.to(device)
            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, targets)
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    acc = 100. * correct / total
    log_info(f"{name} Result | Loss: {total_loss / len(loader):.4f} | Acc: {acc:.2f}%")
    return acc


if __name__ == "__main__":
    torch.multiprocessing.freeze_support()
    train_model()