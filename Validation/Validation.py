import os
import json
import time
import re
import numpy as np
import torch
import torch.nn as nn
import warnings

warnings.filterwarnings('ignore')


# ===================== é…ç½® =====================
class Config:
    # æ¨¡å‹å’Œæ˜ å°„æ–‡ä»¶è·¯å¾„ (å¯¹åº”è®­ç»ƒæ—¶çš„è¾“å‡ºç›®å½•)
    MODEL_PATH = "../src/modulation_dataset_50overlap/best_model.pth"
    MAPPING_PATH = "../src/modulation_dataset_50overlap/label_mapping.json"

    # åŸå§‹æ•°æ®ç›®å½• (ä½ è¦éªŒè¯çš„æ–‡ä»¶å¤¹)
    RAW_DATA_DIR = "../../DataSet"

    # é‡‡æ ·å‚æ•°
    SAMPLE_LENGTH = 4096
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


config = Config()


# ===================== 1. æ¨¡å‹å®šä¹‰ (å¿…é¡»ä¸è®­ç»ƒä»£ç ä¸€è‡´) =====================
class Swish(nn.Module):
    def forward(self, x): return x * torch.sigmoid(x)


def get_activation():
    return nn.SiLU() if hasattr(nn, 'SiLU') else Swish()


class YOLO12_1D_Modulation(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        # Backbone
        self.features = nn.Sequential(
            nn.Conv1d(2, 32, 7, stride=2, padding=3, bias=False),
            nn.BatchNorm1d(32), get_activation(),
            nn.Conv1d(32, 64, 5, stride=2, padding=2, bias=False),
            nn.BatchNorm1d(64), get_activation(),
            nn.Dropout1d(0.1),
            nn.Conv1d(64, 128, 3, stride=2, padding=1, bias=False),
            nn.BatchNorm1d(128), get_activation(),
            nn.Conv1d(128, 256, 3, stride=2, padding=1, bias=False),
            nn.BatchNorm1d(256), get_activation(),
            nn.Conv1d(256, 512, 3, stride=2, padding=1, bias=False),
            nn.BatchNorm1d(512), get_activation(),
            nn.Conv1d(512, 512, 3, stride=2, padding=1, bias=False),
            nn.BatchNorm1d(512), get_activation(),
        )
        # Head
        self.avgpool = nn.AdaptiveAvgPool1d(1)
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512, 256),
            nn.LayerNorm(256),
            get_activation(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        return self.classifier(x)


# ===================== 2. åŸå§‹æ–‡ä»¶é¢„å¤„ç† =====================
def load_and_preprocess_raw_file(file_path, sample_length=4096):
    """
    è¯»å–åŸå§‹ .bin æˆ– .wav æ–‡ä»¶ï¼Œæå–ä¸­é—´ä¸€æ®µè¿›è¡Œå½’ä¸€åŒ–å¤„ç†
    """
    filename = os.path.basename(file_path)
    ext = os.path.splitext(filename)[1].lower()

    try:
        # 1. è¯»å–äºŒè¿›åˆ¶æ•°æ®
        if ext == '.bin':
            # BINæ–‡ä»¶ï¼šç›´æ¥è¯»å–
            with open(file_path, 'rb') as f:
                raw_data = np.fromfile(f, dtype=np.int16)
        elif ext == '.wav':
            # WAVæ–‡ä»¶ï¼šè·³è¿‡1068å­—èŠ‚å¤´
            with open(file_path, 'rb') as f:
                f.seek(1068)
                raw_data = np.fromfile(f, dtype=np.int16)
        else:
            return None, "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"

        # 2. æ£€æŸ¥é•¿åº¦
        iq_pairs = len(raw_data) // 2
        if iq_pairs < sample_length:
            return None, f"æ ·æœ¬è¿‡çŸ­ ({iq_pairs} < {sample_length})"

        # 3. æˆªå–ä¸­é—´ä¸€æ®µ (é¿å…æ–‡ä»¶å¤´å°¾çš„å™ªå£°)
        # æˆ–è€…ä½ å¯ä»¥æ”¹ä¸ºéšæœºæˆªå– start = np.random.randint(0, iq_pairs - sample_length)
        start_idx = (iq_pairs - sample_length) // 2
        seek_pos = start_idx * 2  # int16æ•°ç»„ç´¢å¼•

        extracted = raw_data[seek_pos: seek_pos + sample_length * 2]

        # 4. Reshape [L, 2] -> Transpose [2, L]
        iq_data = extracted.reshape(-1, 2).T

        # 5. å½’ä¸€åŒ– (int16 -> float32 [-1, 1])
        iq_data = iq_data.astype(np.float32) / 32767.0

        # 6. è½¬ Tensor å¹¶å¢åŠ  Batch ç»´åº¦ [1, 2, 4096]
        input_tensor = torch.from_numpy(iq_data).unsqueeze(0)

        return input_tensor, "Success"

    except Exception as e:
        return None, str(e)


# ===================== 3. æ¨ç†æ ¸å¿ƒé€»è¾‘ =====================
class InferenceEngine:
    def __init__(self):
        print(f"â³ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ (Device: {config.DEVICE})...")

        # åŠ è½½æ ‡ç­¾æ˜ å°„
        with open(config.MAPPING_PATH, 'r', encoding='utf-8') as f:
            mapping = json.load(f)
            # å…¼å®¹æ—§ç‰ˆjsonæ ¼å¼
            if 'label_to_idx' in mapping:
                self.idx_to_label = {v: k for k, v in mapping['label_to_idx'].items()}
            else:
                self.idx_to_label = {v: k for k, v in mapping.items()}
            self.num_classes = len(self.idx_to_label)

        # åˆå§‹åŒ–æ¨¡å‹
        self.model = YOLO12_1D_Modulation(num_classes=self.num_classes).to(config.DEVICE)

        # åŠ è½½æƒé‡
        checkpoint = torch.load(config.MODEL_PATH, map_location=config.DEVICE)
        # å¦‚æœä¿å­˜çš„æ˜¯æ•´ä¸ªcheckpointå­—å…¸
        if 'model_state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['model_state_dict'])
            acc = checkpoint.get('best_val_acc', 0.0)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (Val Acc: {acc:.2%})")
        else:
            # å¦‚æœåªä¿å­˜äº†state_dict
            self.model.load_state_dict(checkpoint)
            print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")

        self.model.eval()

    def predict(self, file_path):
        input_tensor, msg = load_and_preprocess_raw_file(file_path, config.SAMPLE_LENGTH)
        if input_tensor is None:
            return None, msg

        input_tensor = input_tensor.to(config.DEVICE)

        start_time = time.time()
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probs = torch.softmax(outputs, dim=1)  # è®¡ç®—æ¦‚ç‡

        elapsed = (time.time() - start_time) * 1000  # ms

        # è·å– Top-3 ç»“æœ
        topk_probs, topk_indices = torch.topk(probs, 3)

        results = []
        for i in range(3):
            idx = topk_indices[0][i].item()
            prob = topk_probs[0][i].item()
            label = self.idx_to_label.get(idx, "Unknown")
            results.append((label, prob))

        return results, elapsed


# ===================== ä¸»ç¨‹åº =====================
if __name__ == "__main__":
    if not os.path.exists(config.MODEL_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {config.MODEL_PATH}")
        exit()

    engine = InferenceEngine()

    # è·å–æ‰€æœ‰åŸå§‹æ–‡ä»¶
    files = [f for f in os.listdir(config.RAW_DATA_DIR) if f.endswith(('.bin', '.wav'))]
    if not files:
        print(f"âŒ ç›®å½• {config.RAW_DATA_DIR} ä¸‹æ²¡æœ‰æ‰¾åˆ° .bin æˆ– .wav æ–‡ä»¶")
        exit()

    # éšæœºé€‰å– 10 ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•
    import random

    random.shuffle(files)
    test_files = files[:10]

    print("\n" + "=" * 80)
    print(f"ğŸš€ å¼€å§‹éªŒè¯ (éšæœºæŠ½å– {len(test_files)} ä¸ªåŸå§‹æ–‡ä»¶)")
    print("=" * 80)
    print(f"{'æ–‡ä»¶å':<35} | {'çœŸå®æ ‡ç­¾ (Guess)':<15} | {'é¢„æµ‹ç»“æœ (Top-1)':<15} | {'ç½®ä¿¡åº¦':<8} | {'ç»“æœ':<5}")
    print("-" * 95)

    correct_count = 0

    for filename in test_files:
        file_path = os.path.join(config.RAW_DATA_DIR, filename)

        # ä»æ–‡ä»¶åçŒœæµ‹çœŸå®æ ‡ç­¾ (å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º "QPSK_xxxx.bin")
        ground_truth = filename.split('_')[0]

        results, elapsed = engine.predict(file_path)

        if results:
            top1_label, top1_prob = results[0]

            # ç®€å•åˆ¤æ–­å¯¹é”™ (ä¸åŒºåˆ†å¤§å°å†™)
            is_correct = ground_truth.lower() in top1_label.lower() or top1_label.lower() in ground_truth.lower()
            status = "âœ…" if is_correct else "âŒ"
            if is_correct: correct_count += 1

            # æ ¼å¼åŒ–è¾“å‡º
            fname_short = (filename[:32] + '..') if len(filename) > 32 else filename
            print(f"{fname_short:<35} | {ground_truth:<15} | {top1_label:<15} | {top1_prob:.1%} | {status}")

            # å¦‚æœé”™è¯¯ï¼Œæ˜¾ç¤º Top-2 å’Œ Top-3
            if not is_correct:
                print(
                    f"   â†³ Top-2: {results[1][0]} ({results[1][1]:.1%}) | Top-3: {results[2][0]} ({results[2][1]:.1%})")
        else:
            print(f"{filename:<35} | è¯»å–å¤±è´¥: {elapsed}")

    print("-" * 95)
    print(f"ğŸ“Š ç»Ÿè®¡: æ­£ç¡® {correct_count}/{len(test_files)} | å‡†ç¡®ç‡: {correct_count / len(test_files):.1%}")